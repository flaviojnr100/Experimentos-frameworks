{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":975},"executionInfo":{"elapsed":6797,"status":"ok","timestamp":1678586172263,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"zbw7XRO_jnlJ","outputId":"8ce76212-6b8d-4103-a774-51f2643d5244"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cherche\n","  Using cached cherche-1.0.1-py3-none-any.whl\n","Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.2.1)\n","Requirement already satisfied: river>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.15.0)\n","Requirement already satisfied: faiss-cpu>=1.7.1.post3 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.7.3)\n","Requirement already satisfied: more-itertools>=9.0.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (9.1.0)\n","Requirement already satisfied: rapidfuzz>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (2.13.7)\n","Requirement already satisfied: sentence-transformers>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (2.2.2)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.24.2)\n","Requirement already satisfied: elasticsearch>=7.10.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (8.6.2)\n","Requirement already satisfied: implicit>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.6.2)\n","Requirement already satisfied: flashtext>=2.7 in /usr/local/lib/python3.9/dist-packages (from cherche) (2.7)\n","Requirement already satisfied: rank-bm25==0.2.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.2.1)\n","Requirement already satisfied: transformers>=4.12.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (4.26.1)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.10.1)\n","Requirement already satisfied: typesense>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.15.1)\n","Requirement already satisfied: meilisearch>=0.22.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.25.0)\n","Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.9/dist-packages (from cherche) (4.65.0)\n","Requirement already satisfied: lunr>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.6.2)\n","Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.9/dist-packages (from elasticsearch>=7.10.0->cherche) (8.4.0)\n","Requirement already satisfied: camel-converter[pydantic] in /usr/local/lib/python3.9/dist-packages (from meilisearch>=0.22.1->cherche) (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from meilisearch>=0.22.1->cherche) (2.25.1)\n","Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from river>=0.8.0->cherche) (1.3.5)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0->cherche) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0->cherche) (3.1.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (0.1.97)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (0.13.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (1.13.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (0.14.1+cu116)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (3.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (0.13.2)\n","Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.9/dist-packages (from elastic-transport<9,>=8->elasticsearch>=7.10.0->cherche) (1.26.14)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from elastic-transport<9,>=8->elasticsearch>=7.10.0->cherche) (2022.12.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.1.0->cherche) (4.5.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->river>=0.8.0->cherche) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->river>=0.8.0->cherche) (2.8.2)\n","Requirement already satisfied: pydantic>=1.8.2 in /usr/local/lib/python3.9/dist-packages (from camel-converter[pydantic]->meilisearch>=0.22.1->cherche) (1.10.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=2.1.0->cherche) (8.1.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->meilisearch>=0.22.1->cherche) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->meilisearch>=0.22.1->cherche) (2.10)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=2.1.0->cherche) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3->river>=0.8.0->cherche) (1.15.0)\n","Installing collected packages: cherche\n","Successfully installed cherche-1.0.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cherche"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install cherche"],"id":"zbw7XRO_jnlJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XURLOOqZf63h"},"outputs":[],"source":["from cherche import retrieve"],"id":"XURLOOqZf63h"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2042,"status":"ok","timestamp":1678586205590,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"790501b1","outputId":"ecd13196-a870-4e95-b9f5-f6959e161b78"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package rslp to /root/nltk_data...\n","[nltk_data]   Unzipping stemmers/rslp.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\n","import pandas as pd\n","\n","from nltk.tokenize import word_tokenize\n","from string import punctuation\n","import nltk\n","from unicodedata import normalize\n","from nltk.stem import RSLPStemmer\n","from nltk.util import ngrams\n","from nltk.tokenize import RegexpTokenizer\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('rslp')\n","\n"],"id":"790501b1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Lz891-Ya7W8"},"outputs":[],"source":[],"id":"3Lz891-Ya7W8"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24566,"status":"ok","timestamp":1678586230153,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"5ce8c7ac","outputId":"f7c5728f-a1b6-4660-d2f1-48c22b146448"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","caminho_query = \"/content/gdrive/MyDrive/Colab Notebooks/dados-conle-anonimizado-assunto-notnull (1).csv\""],"id":"5ce8c7ac"},{"cell_type":"markdown","metadata":{"id":"bc1da4b4"},"source":["# Base de dados câmara dos deputados"],"id":"bc1da4b4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"64586109"},"outputs":[],"source":["df = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/proposicao-tema-completo.csv\")"],"id":"64586109"},{"cell_type":"code","execution_count":null,"metadata":{"id":"80c647da"},"outputs":[],"source":["df_assunto= pd.read_csv(caminho_query, encoding='utf-8', delimiter=\";\")"],"id":"80c647da"},{"cell_type":"code","execution_count":null,"metadata":{"id":"43732db4"},"outputs":[],"source":["arr_assunto = df_assunto.to_numpy()\n","y,X = arr_assunto[:,0],arr_assunto[:,1]\n","y = [i.strip() for i in y]"],"id":"43732db4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0a5d49f0"},"outputs":[],"source":["def verificar(y,top_n):\n","    for d in top_n:\n","      if y == df.loc[d[\"id\"],\"txtNome\"]:\n","        return 1\n","    return 0"],"id":"0a5d49f0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c25bca8b"},"outputs":[],"source":["def avaliacaoRecall(isPreprocess):\n","\n","    quant_encontrado=0\n","    quant_relevante =0\n","    for l,x in zip(y,X):\n","\n","        tokenized_query3 = x                   \n","        if isPreprocess:\n","            tokenized_query3 = preprocess(x)\n","    \n","        top_n = retriever(tokenized_query3)\n","        #top_n = [df.loc[d[\"id\"],\"name\"] for d in top_n_stem_l]\n","\n","        \n","        quant_relevante+=1\n","        quant_encontrado+=verificar(l,top_n)\n","    \n","    recall = quant_encontrado / quant_relevante\n","    print(\"R@20: \"+str(recall))\n"],"id":"c25bca8b"},{"cell_type":"markdown","metadata":{"id":"de7de317"},"source":["# Stemming"],"id":"de7de317"},{"cell_type":"markdown","metadata":{"id":"2e88d729"},"source":["## 6- Stemming (RSLP)"],"id":"2e88d729"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a2518f8"},"outputs":[],"source":["def preprocess(txt):\n","\n","    stemmer = RSLPStemmer()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt)\n","    terms = [stemmer.stem(word) for word in terms]\n","    terms = \" \".join(terms)\n","    return terms"],"id":"4a2518f8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f847fc3a"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n"],"id":"f847fc3a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c13346c2"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"], documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"c13346c2"},{"cell_type":"markdown","metadata":{"id":"a3dab89e"},"source":["Recall"],"id":"a3dab89e"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5e732d82","outputId":"a22edbe1-c5c2-476a-e1cd-7d3d4f73abdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.5016949152542373\n"]}],"source":["avaliacaoRecall(True)"],"id":"5e732d82"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"a09b6dff"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"a09b6dff"},{"cell_type":"markdown","metadata":{"id":"00099533"},"source":["## 7- Stemming (RSLP-S)"],"id":"00099533"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5854aafb"},"outputs":[],"source":["class RSLP_S:\n","    def __plural_reduction(self, word):\n","        excep = [\"lápis\",\"cais\",\"mais\",\"crúcis\",\"biquínis\",\"pois\",\"depois\",\"dois\",\"leis\" ]\n","        excep_s = [\"aliás\",\"pires\",\"lápis\",\"cais\",\"mais\",\"mas\",\"menos\", \"férias\",\"fezes\",\"pêsames\",\"crúcis\",\"gás\", \"atrás\",\"moisés\",\"através\",\"convés\",\"ês\", \"país\",\"após\",\"ambas\",\"ambos\",\"messias\"]\n","\n","        len_word = len(word)\n","        new_word = list(word)\n","\n","        if len_word >= 3:\n","            if new_word[-1] == 's' and new_word[-2] == 'n':\n","                new_word[-2] = 'm'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'õ':\n","                new_word[-3] = 'ã'\n","                new_word[-2] = 'o'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return  sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'ã':\n","                if word == 'mães':\n","                    word = word[:-1]\n","                    return word\n","                else:\n","                    new_word[-2] = 'o'\n","                    sing = \"\".join(new_word)\n","                    sing = sing[:-1]\n","                    return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'a':\n","                if word != 'cais' and word != 'mais':\n","                    new_word[-2] = 'l'\n","                    sing = \"\".join(new_word)\n","                    sing = sing[:-1]\n","                    return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'é':\n","                new_word[-3] = 'e'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'e':\n","                new_word[-3] = 'e'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'ó':\n","                new_word[-3] = 'o'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i':\n","                if word not in excep:\n","                    new_word[-1] = 'l'\n","                    sing = \"\".join(new_word)\n","                    return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'l':\n","                word = word[:-2]\n","                return word\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'r':\n","                word = word[:-2]\n","                return word\n","\n","            if new_word[-1] == 's':\n","                if word not in excep_s:\n","                    word = word[:-1]\n","\n","        return word\n","\n","    def stem(self, word):\n","        word = self.__plural_reduction(word)\n","\n","        return word"],"id":"5854aafb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"15732163"},"outputs":[],"source":["def preprocess(txt):\n","\n","    stemmer = RSLP_S()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt)\n","    terms = [stemmer.stem(word) for word in terms]\n","    terms = \" \".join(terms)\n","    return terms"],"id":"15732163"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"697ac0e3"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n","\n","\n"],"id":"697ac0e3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9ff86e2e"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"], documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"9ff86e2e"},{"cell_type":"markdown","metadata":{"id":"fb22dc26"},"source":["Recall"],"id":"fb22dc26"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d4642c9c","outputId":"65156f51-6338-470e-b482-0bab6c3eb24a"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.43728813559322033\n"]}],"source":["avaliacaoRecall(True)"],"id":"d4642c9c"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"f5c57749"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"f5c57749"},{"cell_type":"markdown","metadata":{"id":"587fec55"},"source":["## 8- Stemming (Savoy)"],"id":"587fec55"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9a2cef58"},"outputs":[],"source":["class Savoy:\n","\n","    def __removeAllPTAccent(self, old_word):\n","        word = list(old_word)\n","        len_word = len(word)-1\n","        for i in range(len_word, -1, -1):\n","            if word[i] == 'ä':\n","                word[i] = 'a'\n","            if word[i] == 'â':\n","                word[i] = 'a'\n","            if word[i] == 'à':\n","                word[i] = 'a'\n","            if word[i] == 'á':\n","                word[i] = 'a'\n","            if word[i] == 'ã':\n","                word[i] = 'a'\n","            if word[i] == 'ê':\n","                word[i] = 'e'\n","            if word[i] == 'é':\n","                word[i] = 'e'\n","            if word[i] == 'è':\n","                word[i] = 'e'\n","            if word[i] == 'ë':\n","                word[i] = 'e'\n","            if word[i] == 'ï':\n","                word[i] = 'i'\n","            if word[i] == 'î':\n","                word[i] = 'i'\n","            if word[i] == 'ì':\n","                word[i] = 'i'\n","            if word[i] == 'í':\n","                word[i] = 'i'\n","            if word[i] == 'ü':\n","                word[i] = 'u'\n","            if word[i] == 'ú':\n","                word[i] = 'u'\n","            if word[i] == 'ù':\n","                word[i] = 'u'\n","            if word[i] == 'û':\n","                word[i] = 'u'\n","            if word[i] == 'ô':\n","                word[i] = 'o'\n","            if word[i] == 'ö':\n","                word[i] = 'o'\n","            if word[i] == 'ó':\n","                word[i] = 'o'\n","            if word[i] == 'ò':\n","                word[i] = 'o'\n","            if word[i] == 'õ':\n","                word[i] = 'o'\n","            if word[i] == 'ç':\n","                word[i] = 'c'\n","\n","        new_word = \"\".join(word)\n","        return new_word\n","\n","    def __finalVowelPortuguese(self, word):\n","        len_word = len(word)\n","        if len_word > 3:\n","            if word[-1] == 'e' or word[-1] == 'a' or word[-1] == 'o':\n","                word = word[:-1]\n","\n","        return word\n","\n","    def __remove_PTsuffix(self, word):\n","        len_word = len(word)\n","\n","        if len_word > 3:\n","            if word[-1] == 's' and word[-2] == 'e' and (word[-3] == 'r' or word[-3] == 's' or word[-3] == 'z' or word[-3] == 'l'):\n","                word = word[:-2]\n","                return word\n","        if len_word > 2:\n","            if word[-1] == 's' and word[-2] == 'n':\n","                new_word = list(word)\n","                new_word[-2] = 'm'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","        if len_word > 3:\n","            if (word[-1] == 's' and word[-2] == 'i') and (word[-3] == 'e' or word[-3] == 'é'):\n","                new_word = list(word)\n","                new_word[-3] = 'e'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","        if len_word > 3:\n","            if word[-1] == 's' and word[-2] == 'i' and word[-3] == 'a':\n","                new_word = list(word)\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","        if len_word > 3:\n","            if word[-1] == 's' and word[-2] == 'i' and word[-3] == 'ó':\n","                new_word = list(word)\n","                new_word[-3] = 'o'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","        if len_word > 3:\n","            if word[-1] == 's' and word[-2] == 'i':\n","                new_word = list(word)\n","                new_word[-1] = 'l'\n","                sing = \"\".join(new_word)\n","                return sing\n","\n","        if len_word > 2:\n","            if word[-1] == 's' and word[-2] == 'e' and word[-3] == 'õ':\n","                new_word = list(word)\n","                new_word[-3] = 'ã'\n","                new_word[-2] = 'o'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","            if word[-1] == 's' and word[-2] == 'e' and word[-3] == 'ã':\n","                new_word = list(word)\n","                new_word[-2] = 'o'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","        if len_word > 5:\n","            if word[-1] == 'e' and word[-2] == 't' and word[-3] == 'n' and word[-4] == 'e' and word[-5] == 'm':\n","                word = word[:-5]\n","                return word\n","\n","        if len_word > 2:\n","            if word[-1] == 's':\n","                word = word[:-1]\n","\n","        return word\n","\n","    def __normFemininPortuguese(self, word):\n","\n","        len_word = len(word)\n","\n","        if len_word < 3 or word[-1] != 'a':\n","            return word\n","\n","        if len_word > 6:\n","\n","            if word[-2] == 'h' and word[-3] == 'n' and word[-4] == 'i':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'c' and word[-3] == 'a' and word[-4] == 'i':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'r' and word[-3] == 'i' and word[-4] == 'e':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","        if len_word > 5:\n","            if word[-2] == 'n' and word[-3] == 'o':\n","                new_word = list(word)\n","                new_word[-3] = 'ã'\n","                new_word[-2] = 'o'\n","                masc = \"\".join(new_word)\n","                masc = masc[:-1]\n","                return masc\n","\n","            if word[-2] == 'r' and word[-3] == 'o':\n","                word = word[:-1]\n","                return word\n","\n","            if word[-2] == 's' and word[-3] == 'o':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 's' and word[-3] == 'e':\n","                new_word = list(word)\n","                new_word[-3] = 'ê'\n","                masc = \"\".join(new_word)\n","                masc = masc[:-1]\n","                return masc\n","\n","            if word[-2] == 'c' and word[-3] == 'i':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'd' and word[-3] == 'i':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'd' and word[-3] == 'a':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'v' and word[-3] == 'i':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'm' and word[-3] == 'a':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","            if word[-2] == 'n':\n","                new_word = list(word)\n","                new_word[-1] = 'o'\n","                masc = \"\".join(new_word)\n","                return masc\n","\n","        return word\n","\n","    def stem(self, word):\n","        len_word = len(word)\n","        if len_word > 2:\n","            word = self.__remove_PTsuffix(word)\n","            word = self.__normFemininPortuguese(word)\n","            word = self.__finalVowelPortuguese(word)\n","            word = self.__removeAllPTAccent(word)\n","\n","        return word\n"],"id":"9a2cef58"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"91e04f6d"},"outputs":[],"source":["def preprocess(txt):\n","\n","    stemmer = Savoy()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt)\n","    terms = [stemmer.stem(word) for word in terms]\n","    terms = \" \".join(terms)\n","    return terms"],"id":"91e04f6d"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"95b7e12c"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n"],"id":"95b7e12c"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3a179916"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"], documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"3a179916"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UguYR7GblFzl","outputId":"c0dd4a31-c2d2-495b-e2f5-4621593e1272"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.43728813559322033\n"]}],"source":["avaliacaoRecall(True)"],"id":"UguYR7GblFzl"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mU1mWYq2lJPw"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"mU1mWYq2lJPw"},{"cell_type":"markdown","metadata":{"id":"7dc20656"},"source":["Recall"],"id":"7dc20656"},{"cell_type":"markdown","metadata":{"id":"8a3416b7"},"source":["## 9- Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword + stemming (RSLP)"],"id":"8a3416b7"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2f35f4a7"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n","    stopwords.extend(list(punctuation))\n","\n","    stemmer = RSLPStemmer()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","        \n","    return \" \".join(terms)"],"id":"2f35f4a7"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"deafcac6"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n"],"id":"deafcac6"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"255bb384"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"], documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"255bb384"},{"cell_type":"markdown","metadata":{"id":"cf160a12"},"source":["Recall"],"id":"cf160a12"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"702975bd","outputId":"77601f3c-fcca-4ccc-d58d-ad5362896239"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.5457627118644067\n"]}],"source":["avaliacaoRecall(True)"],"id":"702975bd"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nV0XQKxolZ_a"},"outputs":[],"source":["documentos=None\n","retriever = None"],"id":"nV0XQKxolZ_a"},{"cell_type":"markdown","metadata":{"id":"cafff496"},"source":["## 10- Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword + stemming (RSLP-S)"],"id":"cafff496"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"39453aaa"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n","    stopwords.extend(list(punctuation))\n","\n","    stemmer = RSLP_S()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","        \n","    return \" \".join(terms)"],"id":"39453aaa"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fa918f2c"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n"],"id":"fa918f2c"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3a7fb47a"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"], documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"3a7fb47a"},{"cell_type":"markdown","metadata":{"id":"192080cc"},"source":["Recall"],"id":"192080cc"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e019f6d8","outputId":"67bba528-8b6d-4e8a-c1b0-d9653182145f"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.5559322033898305\n"]}],"source":["avaliacaoRecall(True)"],"id":"e019f6d8"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"f1z8i9Qclgm5"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"f1z8i9Qclgm5"},{"cell_type":"markdown","metadata":{"id":"723b9b5c"},"source":["## 11- Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword + stemming (Savoy)"],"id":"723b9b5c"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5c1e4d4b"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n","    stopwords.extend(list(punctuation))\n","\n","    stemmer = Savoy()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","        \n","    return \" \".join(terms)"],"id":"5c1e4d4b"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6ba2c4fd"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n"],"id":"6ba2c4fd"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"67b80af7"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"], documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"67b80af7"},{"cell_type":"markdown","metadata":{"id":"a73d6245"},"source":["Recall"],"id":"a73d6245"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b65137bd"},"outputs":[],"source":["avaliacaoRecall(True)"],"id":"b65137bd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJYVTmaMlj55"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"iJYVTmaMlj55"}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":5}