{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":975},"executionInfo":{"elapsed":5865,"status":"ok","timestamp":1678585098689,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"zbw7XRO_jnlJ","outputId":"f43a9495-34c6-470f-d270-c08d1477937c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cherche\n","  Using cached cherche-1.0.1-py3-none-any.whl\n","Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.2.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.24.2)\n","Requirement already satisfied: rapidfuzz>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (2.13.7)\n","Requirement already satisfied: river>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.15.0)\n","Requirement already satisfied: more-itertools>=9.0.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (9.1.0)\n","Requirement already satisfied: rank-bm25==0.2.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.2.1)\n","Requirement already satisfied: meilisearch>=0.22.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.25.0)\n","Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.9/dist-packages (from cherche) (4.65.0)\n","Requirement already satisfied: flashtext>=2.7 in /usr/local/lib/python3.9/dist-packages (from cherche) (2.7)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.10.1)\n","Requirement already satisfied: faiss-cpu>=1.7.1.post3 in /usr/local/lib/python3.9/dist-packages (from cherche) (1.7.3)\n","Requirement already satisfied: typesense>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.15.1)\n","Requirement already satisfied: sentence-transformers>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (2.2.2)\n","Requirement already satisfied: lunr>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.6.2)\n","Requirement already satisfied: implicit>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from cherche) (0.6.2)\n","Requirement already satisfied: elasticsearch>=7.10.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (8.6.2)\n","Requirement already satisfied: transformers>=4.12.0 in /usr/local/lib/python3.9/dist-packages (from cherche) (4.26.1)\n","Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.9/dist-packages (from elasticsearch>=7.10.0->cherche) (8.4.0)\n","Requirement already satisfied: camel-converter[pydantic] in /usr/local/lib/python3.9/dist-packages (from meilisearch>=0.22.1->cherche) (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from meilisearch>=0.22.1->cherche) (2.25.1)\n","Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from river>=0.8.0->cherche) (1.3.5)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0->cherche) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0->cherche) (3.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (0.14.1+cu116)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (3.7)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (1.13.1+cu116)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (0.1.97)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.1.0->cherche) (0.13.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (0.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.12.0->cherche) (6.0)\n","Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.9/dist-packages (from elastic-transport<9,>=8->elasticsearch>=7.10.0->cherche) (1.26.14)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from elastic-transport<9,>=8->elasticsearch>=7.10.0->cherche) (2022.12.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.1.0->cherche) (4.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->river>=0.8.0->cherche) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->river>=0.8.0->cherche) (2022.7.1)\n","Requirement already satisfied: pydantic>=1.8.2 in /usr/local/lib/python3.9/dist-packages (from camel-converter[pydantic]->meilisearch>=0.22.1->cherche) (1.10.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=2.1.0->cherche) (8.1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->meilisearch>=0.22.1->cherche) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->meilisearch>=0.22.1->cherche) (4.0.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=2.1.0->cherche) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3->river>=0.8.0->cherche) (1.15.0)\n","Installing collected packages: cherche\n","Successfully installed cherche-1.0.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cherche"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install cherche"],"id":"zbw7XRO_jnlJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XURLOOqZf63h"},"outputs":[],"source":["from cherche import retrieve"],"id":"XURLOOqZf63h"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1074,"status":"ok","timestamp":1678585137446,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"790501b1","outputId":"97aa9cc4-c960-4da1-ccaf-9117d2cd0d49"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package rslp to /root/nltk_data...\n","[nltk_data]   Unzipping stemmers/rslp.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\n","import pandas as pd\n","\n","from nltk.tokenize import word_tokenize\n","from string import punctuation\n","import nltk\n","from unicodedata import normalize\n","from nltk.stem import RSLPStemmer\n","from nltk.util import ngrams\n","from nltk.tokenize import RegexpTokenizer\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('rslp')\n","\n"],"id":"790501b1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Lz891-Ya7W8"},"outputs":[],"source":[],"id":"3Lz891-Ya7W8"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20105,"status":"ok","timestamp":1678585157549,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"5ce8c7ac","outputId":"e0ad16dc-517d-46f2-d6c8-58336a23d215"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","caminho_query = \"/content/gdrive/MyDrive/Colab Notebooks/dados-conle-anonimizado-assunto-notnull (1).csv\""],"id":"5ce8c7ac"},{"cell_type":"markdown","metadata":{"id":"bc1da4b4"},"source":["# Base de dados c√¢mara dos deputados"],"id":"bc1da4b4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"64586109"},"outputs":[],"source":["df = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/proposicao-tema-completo.csv\")"],"id":"64586109"},{"cell_type":"code","execution_count":null,"metadata":{"id":"80c647da"},"outputs":[],"source":["df_assunto= pd.read_csv(caminho_query, encoding='utf-8', delimiter=\";\")"],"id":"80c647da"},{"cell_type":"code","execution_count":null,"metadata":{"id":"43732db4"},"outputs":[],"source":["arr_assunto = df_assunto.to_numpy()\n","y,X = arr_assunto[:,0],arr_assunto[:,1]\n","y = [i.strip() for i in y]"],"id":"43732db4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0a5d49f0"},"outputs":[],"source":["def verificar(y,top_n):\n","    for d in top_n:\n","      if y == df.loc[d[\"id\"],\"txtNome\"]:\n","        return 1\n","    return 0"],"id":"0a5d49f0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c25bca8b"},"outputs":[],"source":["def avaliacaoRecall(isPreprocess):\n","\n","    quant_encontrado=0\n","    quant_relevante =0\n","    for l,x in zip(y,X):\n","\n","        tokenized_query3 = x                   \n","        if isPreprocess:\n","            tokenized_query3 = preprocess(x)\n","    \n","        top_n = retriever(tokenized_query3)\n","        #top_n = [df.loc[d[\"id\"],\"name\"] for d in top_n_stem_l]\n","\n","        \n","        quant_relevante+=1\n","        quant_encontrado+=verificar(l,top_n)\n","    \n","    recall = quant_encontrado / quant_relevante\n","    print(\"R@20: \"+str(recall))\n"],"id":"c25bca8b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e67af62"},"outputs":[],"source":["def tokenizer1(doc):\n","    return doc.split(\"\\n\")"],"id":"3e67af62"},{"cell_type":"markdown","metadata":{"id":"760fe05f"},"source":["# Word n-gram + pr√© processamento b√°sico + RSLP"],"id":"760fe05f"},{"cell_type":"markdown","metadata":{"id":"3802f025"},"source":["## 18- Letra m√≠nuscula + remo√ß√£o de pontua√ß√£o, acentua√ß√£o e stopword + stemming (RSLP) + bigram"],"id":"3802f025"},{"cell_type":"code","execution_count":null,"metadata":{"id":"de8a0423"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = list(punctuation)\n","\n","    stemmer = RSLPStemmer()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","    \n","    ngram = []\n","    ngram_2 = list(ngrams(terms, 2))\n","        \n","    for w in ngram_2:\n","        string = w[0] + \" \" + w[1]\n","        ngram.append(string)\n","    \n","    return \"\\n\".join(ngram)"],"id":"de8a0423"},{"cell_type":"code","execution_count":null,"metadata":{"id":"be28b58d"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n"],"id":"be28b58d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"da46f32b"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"],tokenizer=tokenizer1, documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"da46f32b"},{"cell_type":"markdown","metadata":{"id":"2de56ead"},"source":["Recall"],"id":"2de56ead"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1883046,"status":"ok","timestamp":1678591734127,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"},"user_tz":180},"id":"0062628a","outputId":"22f58127-8e88-457a-b973-da6623a9ccc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.5254237288135594\n"]}],"source":["avaliacaoRecall(True)"],"id":"0062628a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7abf76b"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"d7abf76b"},{"cell_type":"markdown","metadata":{"id":"45c23d65"},"source":["## 19- Letra m√≠nuscula + remo√ß√£o de pontua√ß√£o, acentua√ß√£o e stopword + stemming (RSLP) + trigram"],"id":"45c23d65"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3edfdd7"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = list(punctuation)\n","\n","    stemmer = RSLPStemmer()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","    \n","    ngram = []\n","    ngram_3 = list(ngrams(terms, 3))\n","        \n","    for w in ngram_3:\n","        string = w[0] + \" \" + w[1] + \" \" + w[2]\n","        ngram.append(string)\n","    \n","    return \"\\n\".join(ngram)"],"id":"a3edfdd7"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"c1161d8e"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n","\n"],"id":"c1161d8e"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9e467a2d"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"],tokenizer=tokenizer1, documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"9e467a2d"},{"cell_type":"markdown","metadata":{"id":"4c492e13"},"source":["Recall"],"id":"4c492e13"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d82bf3e4","outputId":"fead627f-1654-468a-b478-aa42c31fa171"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.4\n"]}],"source":["avaliacaoRecall(True)"],"id":"d82bf3e4"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6b8df5bb"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"6b8df5bb"},{"cell_type":"markdown","metadata":{"id":"e72f9f64"},"source":["## 20- Letra m√≠nuscula + remo√ß√£o de pontua√ß√£o, acentua√ß√£o e stopword + stemming (RSLP) + unigram + bigram"],"id":"e72f9f64"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"04344d9e"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = list(punctuation)\n","\n","    stemmer = RSLPStemmer()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","    \n","    ngram = []\n","    ngram_1 = list(ngrams(terms, 1))\n","    ngram_2 = list(ngrams(terms, 2))\n","    for w in ngram_1:\n","        ngram.append(w[0])\n","        \n","    for w in ngram_2:\n","        string = w[0] + \" \" + w[1]\n","        ngram.append(string)\n","    \n","    return \"\\n\".join(ngram)\n"],"id":"04344d9e"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0ce68478"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n","\n"],"id":"0ce68478"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2e7c755d"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"],tokenizer=tokenizer1, documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"2e7c755d"},{"cell_type":"markdown","metadata":{"id":"fd1c2022"},"source":["Recall"],"id":"fd1c2022"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c870f0f5"},"outputs":[],"source":["avaliacaoRecall(True)"],"id":"c870f0f5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9af91c4"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"c9af91c4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kK8MzAqjilm"},"outputs":[],"source":[],"id":"5kK8MzAqjilm"},{"cell_type":"markdown","metadata":{"id":"W4dKtSikjkTK"},"source":["# Word n-gram + pr√© processamento b√°sico + RSLPS"],"id":"W4dKtSikjkTK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-Q6AxC0kAYA"},"outputs":[],"source":["class RSLP_S:\n","    def __plural_reduction(self, word):\n","        excep = [\"l√°pis\",\"cais\",\"mais\",\"cr√∫cis\",\"biqu√≠nis\",\"pois\",\"depois\",\"dois\",\"leis\" ]\n","        excep_s = [\"ali√°s\",\"pires\",\"l√°pis\",\"cais\",\"mais\",\"mas\",\"menos\", \"f√©rias\",\"fezes\",\"p√™sames\",\"cr√∫cis\",\"g√°s\", \"atr√°s\",\"mois√©s\",\"atrav√©s\",\"conv√©s\",\"√™s\", \"pa√≠s\",\"ap√≥s\",\"ambas\",\"ambos\",\"messias\"]\n","\n","        len_word = len(word)\n","        new_word = list(word)\n","\n","        if len_word >= 3:\n","            if new_word[-1] == 's' and new_word[-2] == 'n':\n","                new_word[-2] = 'm'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == '√µ':\n","                new_word[-3] = '√£'\n","                new_word[-2] = 'o'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return  sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == '√£':\n","                if word == 'm√£es':\n","                    word = word[:-1]\n","                    return word\n","                else:\n","                    new_word[-2] = 'o'\n","                    sing = \"\".join(new_word)\n","                    sing = sing[:-1]\n","                    return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'a':\n","                if word != 'cais' and word != 'mais':\n","                    new_word[-2] = 'l'\n","                    sing = \"\".join(new_word)\n","                    sing = sing[:-1]\n","                    return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == '√©':\n","                new_word[-3] = 'e'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'e':\n","                new_word[-3] = 'e'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == '√≥':\n","                new_word[-3] = 'o'\n","                new_word[-2] = 'l'\n","                sing = \"\".join(new_word)\n","                sing = sing[:-1]\n","                return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'i':\n","                if word not in excep:\n","                    new_word[-1] = 'l'\n","                    sing = \"\".join(new_word)\n","                    return sing\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'l':\n","                word = word[:-2]\n","                return word\n","\n","            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'r':\n","                word = word[:-2]\n","                return word\n","\n","            if new_word[-1] == 's':\n","                if word not in excep_s:\n","                    word = word[:-1]\n","\n","        return word\n","\n","    def stem(self, word):\n","        word = self.__plural_reduction(word)\n","\n","        return word"],"id":"C-Q6AxC0kAYA"},{"cell_type":"markdown","metadata":{"id":"1r_QG8eEjkTK"},"source":["## 18- Letra m√≠nuscula + remo√ß√£o de pontua√ß√£o, acentua√ß√£o e stopword + stemming (RSLPS) + bigram"],"id":"1r_QG8eEjkTK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNM0eW6AjkTK"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = list(punctuation)\n","\n","    stemmer = RSLP_S()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","    \n","    ngram = []\n","    ngram_2 = list(ngrams(terms, 2))\n","        \n","    for w in ngram_2:\n","        string = w[0] + \" \" + w[1]\n","        ngram.append(string)\n","    \n","    return \"\\n\".join(ngram)"],"id":"BNM0eW6AjkTK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3Y2_9_AjkTK"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n"],"id":"Q3Y2_9_AjkTK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQaVflqCjkTL"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"],tokenizer=tokenizer1, documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"OQaVflqCjkTL"},{"cell_type":"markdown","metadata":{"id":"SS4ZN6czjkTL"},"source":["Recall"],"id":"SS4ZN6czjkTL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"60GuDSKijkTL"},"outputs":[],"source":["avaliacaoRecall(True)"],"id":"60GuDSKijkTL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0y4Wx4xfjkTL"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"0y4Wx4xfjkTL"},{"cell_type":"markdown","metadata":{"id":"jcWjgsKTjkTL"},"source":["## 19- Letra m√≠nuscula + remo√ß√£o de pontua√ß√£o, acentua√ß√£o e stopword + stemming (RSLPS) + trigram"],"id":"jcWjgsKTjkTL"},{"cell_type":"code","execution_count":42,"metadata":{"id":"aBo-49iwjkTL","executionInfo":{"status":"ok","timestamp":1678620455389,"user_tz":180,"elapsed":3,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"}}},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = list(punctuation)\n","\n","    stemmer = RSLP_S()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","    \n","    ngram = []\n","    ngram_3 = list(ngrams(terms, 3))\n","        \n","    for w in ngram_3:\n","        string = w[0] + \" \" + w[1] + \" \" + w[2]\n","        ngram.append(string)\n","    \n","    return \"\\n\".join(ngram)"],"id":"aBo-49iwjkTL"},{"cell_type":"code","execution_count":43,"metadata":{"id":"eLgewVrvjkTL","executionInfo":{"status":"ok","timestamp":1678620759977,"user_tz":180,"elapsed":302762,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"}}},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n","\n"],"id":"eLgewVrvjkTL"},{"cell_type":"code","execution_count":44,"metadata":{"id":"5Ehm3NlfjkTL","executionInfo":{"status":"ok","timestamp":1678620925230,"user_tz":180,"elapsed":165257,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"}}},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"],tokenizer=tokenizer1, documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"5Ehm3NlfjkTL"},{"cell_type":"markdown","metadata":{"id":"DqM6080HjkTL"},"source":["Recall"],"id":"DqM6080HjkTL"},{"cell_type":"code","execution_count":45,"metadata":{"id":"CRa3Cdr9jkTM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678622605807,"user_tz":180,"elapsed":1680580,"user":{"displayName":"Flavio Junior","userId":"10524376749994611287"}},"outputId":"1e130e07-bbd1-44b9-b1b4-ec21edb6940c"},"outputs":[{"output_type":"stream","name":"stdout","text":["R@20: 0.3864406779661017\n"]}],"source":["avaliacaoRecall(True)"],"id":"CRa3Cdr9jkTM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzTe7joEjkTM"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"yzTe7joEjkTM"},{"cell_type":"markdown","metadata":{"id":"tWKH69XyjkTM"},"source":["## 20- Letra m√≠nuscula + remo√ß√£o de pontua√ß√£o, acentua√ß√£o e stopword + stemming (RSLPS) + unigram + bigram"],"id":"tWKH69XyjkTM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"O4WMqEwqjkTM"},"outputs":[],"source":["def _remove_acentos(txt):\n","    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n","\n","def preprocess(txt):\n","    txt = _remove_acentos(txt)\n","    stopwords = list(punctuation)\n","\n","    stemmer = RSLP_S()\n","    tokenizer = RegexpTokenizer('\\w+')\n","    terms = tokenizer.tokenize(txt.lower())\n","    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n","    \n","    ngram = []\n","    ngram_1 = list(ngrams(terms, 1))\n","    ngram_2 = list(ngrams(terms, 2))\n","    for w in ngram_1:\n","        ngram.append(w[0])\n","        \n","    for w in ngram_2:\n","        string = w[0] + \" \" + w[1]\n","        ngram.append(string)\n","    \n","    return \"\\n\".join(ngram)\n"],"id":"O4WMqEwqjkTM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iXdNQUPjkTM"},"outputs":[],"source":["documentos = [\n","    {\n","        \"id\":i,\n","        \"name\":str(df.loc[i,\"txtNome\"]).strip(),\n","        \"text\":preprocess(str(df.loc[i,\"imgArquivoTeorPDF\"]))\n","    }\n","\n","   for i in range(len(df))\n","    ]\n","\n","\n","\n"],"id":"2iXdNQUPjkTM"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KNT7lebujkTM"},"outputs":[],"source":["retriever = retrieve.BM25Okapi(key=\"id\", on=[\"text\"],tokenizer=tokenizer1, documents=documentos,k=20,k1=1.5,b=0.75,epsilon=0.25)"],"id":"KNT7lebujkTM"},{"cell_type":"markdown","metadata":{"id":"kSckiOv8jkTM"},"source":["Recall"],"id":"kSckiOv8jkTM"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZpnkCKbmjkTM","outputId":"e0e2da4d-bc75-4891-fb63-5bc1977757b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["R@20: 0.5559322033898305\n"]}],"source":["avaliacaoRecall(True)"],"id":"ZpnkCKbmjkTM"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n9AuiX2FjkTM"},"outputs":[],"source":["documentos = None\n","retriever =None"],"id":"n9AuiX2FjkTM"}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":5}